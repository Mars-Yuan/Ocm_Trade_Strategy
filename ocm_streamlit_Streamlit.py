# ============ OCM Markowitz Streamlit Dashboard ============
# è¿è¡Œæ–¹å¼: streamlit run ocm_streamlit_dashboard.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import yfinance as yf
import json
import os
import re
from datetime import date, datetime, timedelta
try:
    from zoneinfo import ZoneInfo  # Python 3.9+
except ImportError:
    from pytz import timezone as ZoneInfo  # fallback for Python 3.8
from scipy.optimize import minimize


def get_yahoo_current_date():
    """è·å– Yahoo Finance æ•°æ®æºæ—¶åŒºï¼ˆç¾ä¸œæ—¶é—´ï¼‰çš„å½“å‰æ—¥æœŸ"""
    try:
        eastern = ZoneInfo('America/New_York')
        now_eastern = datetime.now(eastern)
        return now_eastern.date()
    except Exception:
        # å¦‚æœæ—¶åŒºè·å–å¤±è´¥ï¼Œå›é€€åˆ°æœ¬æœºæ—¶é—´
        return date.today()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="OCM Markowitz Dashboard",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .metric-card {
        background-color: #1e1e1e;
        border-radius: 10px;
        padding: 20px;
        text-align: center;
    }
    .metric-value {
        font-size: 2rem;
        font-weight: bold;
        color: #00d4aa;
    }
    .metric-label {
        font-size: 0.9rem;
        color: #888;
    }
</style>
""", unsafe_allow_html=True)

# é¢œè‰²ä¸»é¢˜
colors = {
    'optimal': '#ff4444',      # çº¢è‰² - æœ€ä¼˜ç»„åˆ
    'equal': '#44cc44',        # ç»¿è‰² - ç­‰æƒç»„åˆ
    'benchmark': '#4488ff',    # è“è‰² - åŸºå‡†
    'positive': '#00d4aa',
    'negative': '#ff6b6b'
}

# åŠ è½½æ•°æ®ï¼ˆä¸ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡è¯»å–æœ€æ–°æ–‡ä»¶ï¼‰
def load_dashboard_data():
    """ä»ä¿å­˜çš„æ–‡ä»¶åŠ è½½æ•°æ®"""
    data_path = os.path.join(os.path.dirname(__file__), 'Streamlit_data.json')
    
    if not os.path.exists(data_path):
        st.error("âš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼è¯·å…ˆè¿è¡Œ notebook ä¸­çš„æ•°æ®å¯¼å‡º cell")
        st.info("åœ¨ notebook ä¸­è¿è¡Œ 'å¯¼å‡ºæ•°æ®å¹¶å¯åŠ¨ Streamlit' cell ååˆ·æ–°æ­¤é¡µé¢")
        return None
    
    with open(data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data


def period_to_days(period_label):
    text = str(period_label).strip().upper()
    if not text:
        return 1

    match = re.match(r'^(\d+)?\s*([DWMQY])$', text)
    if match:
        num_text, unit = match.groups()
        n = int(num_text) if num_text else 1
        if unit == 'D':
            return max(1, n)
        if unit == 'W':
            return max(1, n * 5)
        if unit == 'M':
            return max(1, n * 21)
        if unit == 'Q':
            return max(1, n * 63)
        if unit == 'Y':
            return max(1, n * 252)

    return 1


def period_to_bars_per_year(period_label):
    days = period_to_days(period_label)
    return max(1, int(round(252 / days)))


def calc_max_drawdown(cum_curve):
    running_max = np.maximum.accumulate(cum_curve)
    drawdown = cum_curve / running_max - 1
    return float(np.min(drawdown)) if len(drawdown) > 0 else 0.0


def calc_perf_stats(daily_returns):
    if len(daily_returns) == 0:
        return 0.0, 0.0, 0.0, 0.0

    cum = (1 + daily_returns).cumprod()
    total_return = float(cum.iloc[-1] - 1)
    n = len(daily_returns)
    ann_return = float((1 + total_return) ** (252 / n) - 1) if n > 0 else 0.0
    vol = float(daily_returns.std())
    sharpe = float((daily_returns.mean() * 252) / (vol * np.sqrt(252))) if vol > 1e-12 else 0.0
    max_dd = calc_max_drawdown(cum.values)
    return total_return, ann_return, sharpe, max_dd


def standardize_daily_df(price_df):
    df = price_df.copy()
    df = df.reset_index()
    
    # è¯†åˆ«æ—¥æœŸåˆ—
    date_col = None
    for c in ['Date', 'date', 'Datetime', 'datetime']:
        if c in df.columns:
            date_col = c
            break
    if date_col is None:
        date_col = df.columns[0]
    df['trade_date'] = pd.to_datetime(df[date_col]).dt.strftime('%Y%m%d')
    
    # åˆ—åæ˜ å°„ï¼ˆæ”¯æŒå¤§å°å†™ä¸æ•æ„Ÿï¼‰
    col_map = {}
    for target, aliases in [
        ('open', ['Open', 'open', 'OPEN']),
        ('high', ['High', 'high', 'HIGH']),
        ('low', ['Low', 'low', 'LOW']),
        ('close', ['Close', 'close', 'CLOSE', 'Adj Close', 'adj close'])
    ]:
        for alias in aliases:
            if alias in df.columns:
                col_map[target] = alias
                break
    
    # ç¡®ä¿è‡³å°‘æœ‰ close åˆ—
    if 'close' not in col_map:
        raise ValueError("DataFrame ç¼ºå°‘ Close åˆ—")
    
    # å¦‚æœç¼ºå°‘ open/high/lowï¼Œç”¨ close å¡«å……
    result = pd.DataFrame()
    result['trade_date'] = df['trade_date']
    result['open'] = df[col_map.get('open', col_map['close'])].astype(float)
    result['high'] = df[col_map.get('high', col_map['close'])].astype(float)
    result['low'] = df[col_map.get('low', col_map['close'])].astype(float)
    result['close'] = df[col_map['close']].astype(float)
    
    return result.reset_index(drop=True)


def resample_ohlc(df, period):
    df = df.copy().reset_index(drop=True)
    groups = []
    for i in range(0, len(df), period):
        g = df.iloc[i:i + period]
        if len(g) == 0:
            continue
        groups.append({
            'trade_date': g['trade_date'].iloc[-1],
            'open': g['open'].iloc[0],
            'high': g['high'].max(),
            'low': g['low'].min(),
            'close': g['close'].iloc[-1]
        })
    return pd.DataFrame(groups)


def generate_ocm_signals(df):
    df = df.copy()
    n = len(df)
    df['prev_close'] = df['close'].shift(1)
    df['breakout'] = df['open'] > df['prev_close']
    signals = np.zeros(n)
    position = 0
    for i in range(1, n):
        if bool(df['breakout'].iloc[i]) and position == 0:
            signals[i] = 1
            position = 1
        elif (not bool(df['breakout'].iloc[i])) and position == 1:
            signals[i] = -1
            position = 0
    df['signal'] = signals
    return df


def backtest_ocm(df):
    df = generate_ocm_signals(df)
    n = len(df)
    daily_returns = np.zeros(n)
    position = 0
    for i in range(1, n):
        signal = df['signal'].iloc[i]
        open_price = df['open'].iloc[i]
        close_price = df['close'].iloc[i]
        prev_close = df['close'].iloc[i - 1]
        if signal == 1:
            position = 1
            daily_returns[i] = (close_price - open_price) / open_price if open_price != 0 else 0
        elif signal == -1:
            position = 0
            daily_returns[i] = 0
        elif position == 1:
            daily_returns[i] = (close_price - prev_close) / prev_close if prev_close != 0 else 0
    return pd.Series(daily_returns, index=df['trade_date'])


def markowitz_optimize(returns_df):
    n_assets = len(returns_df.columns)
    mean_returns = returns_df.mean().values * 252
    cov_matrix = returns_df.cov().values * 252

    def portfolio_return(weights):
        return np.dot(weights, mean_returns)

    def portfolio_volatility(weights):
        return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))

    def neg_sharpe_ratio(weights):
        ret = portfolio_return(weights)
        vol = portfolio_volatility(weights)
        return -ret / vol if vol > 0 else 0

    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
    bounds = tuple((0, 1) for _ in range(n_assets))
    init_weights = np.array([1 / n_assets] * n_assets)

    result = minimize(neg_sharpe_ratio, init_weights, method='SLSQP', bounds=bounds, constraints=constraints)
    if not result.success:
        optimal_weights = init_weights
    else:
        optimal_weights = result.x

    opt_return = portfolio_return(optimal_weights)
    opt_vol = portfolio_volatility(optimal_weights)
    opt_sharpe = opt_return / opt_vol if opt_vol > 0 else 0

    return {
        'weights': optimal_weights,
        'return': float(opt_return),
        'volatility': float(opt_vol),
        'sharpe': float(opt_sharpe),
        'assets': returns_df.columns.tolist()
    }


def portfolio_backtest(returns_df, weights):
    portfolio_returns = (returns_df * weights).sum(axis=1)
    cum_returns = (1 + portfolio_returns).cumprod()
    total_return = float(cum_returns.iloc[-1] - 1) if len(cum_returns) else 0.0
    n_days = len(portfolio_returns)
    ann_return = float((1 + total_return) ** (252 / n_days) - 1) if n_days > 0 else 0.0
    ann_vol = float(portfolio_returns.std() * np.sqrt(252))
    sharpe = float(ann_return / ann_vol) if ann_vol > 0 else 0.0
    peak = cum_returns.cummax()
    drawdown = (peak - cum_returns) / peak
    max_dd = float(drawdown.max()) if len(drawdown) else 0.0
    return {
        'total_return': total_return,
        'ann_return': ann_return,
        'ann_vol': ann_vol,
        'sharpe': sharpe,
        'max_drawdown': max_dd,
        'portfolio_returns': portfolio_returns,
        'cum_returns': cum_returns
    }


# ============ æ»šåŠ¨å›æµ‹æ¨¡å¼ ============
# æ»šåŠ¨å›æµ‹å‚æ•°ï¼ˆåŸºäºæœ€é•¿å‘¨æœŸ31Dè®¾è®¡ï¼‰
# å›çœ‹çª—å£ >= æœ€é•¿å‘¨æœŸçš„10å€ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—å„å‘¨æœŸæ”¶ç›Š
LOOKBACK_DAYS = 20      # å›çœ‹çª—å£ï¼ˆä¸ notebook ä¸€è‡´ï¼‰
REBALANCE_DAYS = 5      # å†å¹³è¡¡å‘¨æœŸï¼ˆæ¯5å¤©è°ƒä»“ï¼‰
MIN_LOOKBACK = 15       # æœ€å°å›çœ‹å¤©æ•°ï¼ˆä¸ notebook ä¸€è‡´ï¼‰
DEFAULT_PERIODS = ['1D', '3D', 'W', '11D', '17D', '23D', '31D']


def period_sort_key(period_label):
    text = str(period_label).strip().upper()
    if text in DEFAULT_PERIODS:
        return DEFAULT_PERIODS.index(text)
    return len(DEFAULT_PERIODS) + period_to_days(text)


def rolling_portfolio_backtest(returns_df, lookback=20, rebalance=5, min_lookback=15):
    """
    æ»šåŠ¨å›æµ‹ï¼ˆRolling Backtestï¼‰
    
    å‚æ•°:
    - returns_df: æ”¶ç›Šç‡çŸ©é˜µ
    - lookback: å›çœ‹çª—å£å¤©æ•°ï¼ˆç”¨äºè®¡ç®—æƒé‡ï¼‰
    - rebalance: å†å¹³è¡¡å‘¨æœŸï¼ˆæ¯éš”å¤šå°‘å¤©é‡æ–°ä¼˜åŒ–ï¼‰
    - min_lookback: æœ€å°å›çœ‹å¤©æ•°
    
    è¿”å›:
    - å›æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«ç»„åˆæ”¶ç›Šã€æƒé‡å†å²ç­‰
    """
    n_days = len(returns_df)
    n_assets = len(returns_df.columns)
    
    # åˆå§‹åŒ–
    portfolio_returns = np.zeros(n_days)
    weights_history = []  # è®°å½•æ¯æ¬¡å†å¹³è¡¡çš„æƒé‡
    rebalance_dates = []  # è®°å½•å†å¹³è¡¡æ—¥æœŸ
    
    # å½“å‰æƒé‡ï¼ˆåˆå§‹ç­‰æƒï¼‰
    current_weights = np.array([1/n_assets] * n_assets)
    last_rebalance = 0
    
    for i in range(n_days):
        # è®¡ç®—å½“æ—¥ç»„åˆæ”¶ç›Š
        daily_ret = returns_df.iloc[i].values
        portfolio_returns[i] = np.dot(daily_ret, current_weights)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å†å¹³è¡¡
        if i >= min_lookback and (i - last_rebalance) >= rebalance:
            # ä½¿ç”¨è¿‡å»lookbackå¤©æ•°æ®ä¼˜åŒ–æƒé‡
            start_idx = max(0, i - lookback)
            train_data = returns_df.iloc[start_idx:i]
            
            # æ’é™¤å…¨é›¶è¡Œ
            train_data_valid = train_data.loc[(train_data != 0).any(axis=1)]
            
            if len(train_data_valid) >= min_lookback // 2:
                try:
                    opt_result_rolling = markowitz_optimize(train_data_valid)
                    current_weights = opt_result_rolling['weights']
                    
                    # è®°å½•å†å¹³è¡¡ä¿¡æ¯
                    weights_history.append({
                        'date': returns_df.index[i],
                        'weights': current_weights.copy(),
                        'opt_sharpe': opt_result_rolling['sharpe']
                    })
                    rebalance_dates.append(returns_df.index[i])
                    last_rebalance = i
                except:
                    pass  # ä¼˜åŒ–å¤±è´¥æ—¶ä¿æŒåŸæƒé‡
    
    # è®¡ç®—å›æµ‹æŒ‡æ ‡
    portfolio_returns = pd.Series(portfolio_returns, index=returns_df.index)
    cum_returns = (1 + portfolio_returns).cumprod()
    total_return = float(cum_returns.iloc[-1] - 1) if len(cum_returns) else 0.0
    ann_return = float((1 + total_return) ** (252 / n_days) - 1) if n_days > 0 else 0.0
    ann_vol = float(portfolio_returns.std() * np.sqrt(252))
    sharpe = float(ann_return / ann_vol) if ann_vol > 0 else 0.0
    
    peak = cum_returns.cummax()
    drawdown = (peak - cum_returns) / peak
    max_dd = float(drawdown.max()) if len(drawdown) else 0.0
    
    return {
        'total_return': total_return,
        'ann_return': ann_return,
        'ann_vol': ann_vol,
        'sharpe': sharpe,
        'max_drawdown': max_dd,
        'portfolio_returns': portfolio_returns,
        'cum_returns': cum_returns,
        'weights_history': weights_history,
        'rebalance_dates': rebalance_dates,
        'n_rebalances': len(rebalance_dates)
    }


@st.cache_data(show_spinner=False, ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
def build_runtime_data(symbol, start_date_input, end_date_input, assets, weights):
    start_str = pd.to_datetime(start_date_input).strftime('%Y-%m-%d')
    # yfinance çš„ end å‚æ•°æ˜¯ exclusive çš„ï¼Œéœ€è¦åŠ ä¸€å¤©æ‰èƒ½åŒ…å« end_date å½“å¤©æ•°æ®
    end_str = (pd.to_datetime(end_date_input) + timedelta(days=1)).strftime('%Y-%m-%d')

    # éªŒè¯æ ‡çš„ä»£ç æ˜¯å¦æœ‰æ•ˆï¼ˆä½¿ç”¨ history() æ–¹æ³•æ›´å¯é ï¼‰
    try:
        ticker = yf.Ticker(symbol)
        # ç›´æ¥å°è¯•è·å–å†å²æ•°æ®æ¥éªŒè¯æ ‡çš„æ˜¯å¦å­˜åœ¨
        test_hist = ticker.history(period='5d')
        if test_hist.empty:
            return None, f"æ ‡çš„ä»£ç ï¼ˆæ ¼å¼ï¼‰é”™è¯¯/Yahooæ— æ­¤æ ‡çš„ï¼Œè¯·é‡æ–°è¾“å…¥"
    except Exception as e:
        return None, f"æ ‡çš„ä»£ç éªŒè¯å¤±è´¥: {str(e)}"

    price_df = yf.download(symbol, start=start_str, end=end_str, auto_adjust=True, progress=False)
    if price_df is None or price_df.empty:
        return None, f"æœªè·å–åˆ° {symbol} åœ¨æ‰€é€‰åŒºé—´çš„è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥æ—¥æœŸèŒƒå›´"

    if isinstance(price_df.columns, pd.MultiIndex):
        flat_cols = []
        for col in price_df.columns:
            parts = [str(x) for x in col if str(x).strip() not in ['', 'None']]
            flat_cols.append('_'.join(parts))
        price_df.columns = flat_cols

    def resolve_price_col(target):
        cols = [str(c) for c in price_df.columns]
        lower_map = {c.lower(): c for c in cols}
        if target.lower() in lower_map:
            return lower_map[target.lower()]

        for c in cols:
            cl = c.lower()
            if cl.endswith(f"_{target.lower()}") or cl.startswith(f"{target.lower()}_"):
                return c

        for c in cols:
            if target.lower() in c.lower():
                return c

        return None

    open_col = resolve_price_col('Open')
    close_col = resolve_price_col('Close')

    if open_col is None or close_col is None:
        return None, f"è¡Œæƒ…ç¼ºå°‘å¿…è¦å­—æ®µ: Open/Closeï¼ˆå½“å‰åˆ—: {list(price_df.columns)[:8]}ï¼‰"

    if open_col != 'Open':
        price_df['Open'] = price_df[open_col]
    if close_col != 'Close':
        price_df['Close'] = price_df[close_col]

    price_df = price_df.dropna(subset=['Close']).copy()
    if len(price_df) < 40:
        return None, "æœ‰æ•ˆäº¤æ˜“æ—¥ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç­–ç•¥"

    df_daily_std = standardize_daily_df(price_df)

    # å›ºå®šç­–ç•¥å‘¨æœŸï¼ˆä¸ notebook ä¿æŒä¸€è‡´ï¼‰
    base_periods = DEFAULT_PERIODS
    multi_period_data = {}
    for period_name in base_periods:
        if period_name == '1D':
            multi_period_data['1D'] = df_daily_std.copy()
        else:
            multi_period_data[period_name] = resample_ohlc(df_daily_std, period_to_days(period_name))

    period_returns = {}
    period_stats = []
    for period_name, df_period in multi_period_data.items():
        if len(df_period) < 2:
            continue
        returns = backtest_ocm(df_period)
        period_returns[period_name] = returns

        total_return = float((1 + returns).prod() - 1)
        n_bars = len(returns)
        bars_per_year = period_to_bars_per_year(period_name)
        if n_bars > 0 and total_return > -1:
            ann_return = float((1 + total_return) ** (bars_per_year / n_bars) - 1)
        else:
            ann_return = 0.0
        volatility = float(returns.std() * np.sqrt(bars_per_year))
        sharpe = float(ann_return / volatility) if volatility > 0 else 0.0
        cum_ret = (1 + returns).cumprod()
        peak = cum_ret.cummax()
        drawdown = (peak - cum_ret) / peak
        max_dd = float(drawdown.max()) if len(drawdown) else 0.0

        period_stats.append({
            'å‘¨æœŸ': period_name,
            'Kçº¿æ•°': n_bars,
            'æ€»æ”¶ç›Šç‡': f'{total_return:.2%}',
            'å¹´åŒ–æ”¶ç›Š': f'{ann_return:.2%}',
            'å¹´åŒ–æ³¢åŠ¨': f'{volatility:.2%}',
            'Sharpe': f'{sharpe:.2f}',
            'æœ€å¤§å›æ’¤': f'{max_dd:.2%}'
        })

    period_stats = sorted(period_stats, key=lambda x: period_sort_key(x.get('å‘¨æœŸ', '')))

    if len(period_returns) == 0:
        return None, "æœªç”Ÿæˆæœ‰æ•ˆå‘¨æœŸæ”¶ç›Šåºåˆ—"

    all_dates = set()
    for returns in period_returns.values():
        all_dates.update(returns.index)
    all_dates = sorted(all_dates)

    returns_matrix_full = pd.DataFrame(index=all_dates)
    for period_name, returns in period_returns.items():
        returns_matrix_full[period_name] = returns_matrix_full.index.map(lambda d: returns.get(d, 0.0))

    ordered_cols = [p for p in DEFAULT_PERIODS if p in returns_matrix_full.columns]
    if len(ordered_cols) > 0:
        returns_matrix_full = returns_matrix_full[ordered_cols]

    returns_matrix_opt = returns_matrix_full.loc[(returns_matrix_full != 0).any(axis=1)]
    if len(returns_matrix_opt) < 10:
        return None, "æœ‰æ•ˆæ”¶ç›Šç‡æ ·æœ¬ä¸è¶³ï¼Œæ— æ³•ä¼˜åŒ–æƒé‡"

    n_train = max(1, int(len(returns_matrix_opt) * 0.7))
    returns_matrix_train = returns_matrix_opt.iloc[:n_train]
    if returns_matrix_train.empty:
        return None, "è®­ç»ƒé›†ä¸ºç©ºï¼Œæ— æ³•ä¼˜åŒ–æƒé‡"

    # æ»šåŠ¨å›æµ‹ï¼ˆä¸»ç­–ç•¥ï¼‰- æ›´æ¥è¿‘å®ç›˜
    rolling_result = rolling_portfolio_backtest(
        returns_matrix_full, 
        lookback=LOOKBACK_DAYS, 
        rebalance=REBALANCE_DAYS,
        min_lookback=MIN_LOOKBACK
    )
    
    # å›ºå®šæƒé‡å›æµ‹ï¼ˆå¯¹æ¯”ï¼šä½¿ç”¨è®­ç»ƒé›†ä¼˜åŒ–çš„æƒé‡ï¼‰
    opt_result = markowitz_optimize(returns_matrix_train)
    fixed_result = portfolio_backtest(returns_matrix_full, opt_result['weights'])

    # æ»šåŠ¨å›æµ‹æœ€æ–°æƒé‡ï¼ˆç”¨äºäº¤æ˜“ä¿¡å·ï¼‰
    if rolling_result['weights_history']:
        latest_rolling_weights = rolling_result['weights_history'][-1]['weights']
    else:
        latest_rolling_weights = opt_result['weights']
    
    # ç­‰æƒç»„åˆå›æµ‹ï¼ˆå¯¹æ¯”ï¼‰
    equal_weights = np.array([1 / len(returns_matrix_full.columns)] * len(returns_matrix_full.columns))
    equal_result = portfolio_backtest(returns_matrix_full, equal_weights)
    
    # ä½¿ç”¨æ»šåŠ¨å›æµ‹ç»“æœä½œä¸ºä¸»ç­–ç•¥
    portfolio_result = rolling_result

    benchmark_curve = (df_daily_std['close'].values / df_daily_std['close'].iloc[0])
    benchmark_peak = np.maximum.accumulate(benchmark_curve)
    benchmark_max_dd = float(np.max((benchmark_peak - benchmark_curve) / benchmark_peak)) if len(benchmark_curve) else 0.0

    hm_tail = returns_matrix_full.tail(30)
    returns_heatmap = {
        'dates': [str(d)[-5:] for d in hm_tail.index.tolist()],
        'periods': hm_tail.columns.tolist(),
        'values': hm_tail.values.T.tolist()
    }

    # æ”¶é›†æ‰€æœ‰å‘¨æœŸçš„äº¤æ˜“ä¿¡å·ï¼ˆæŒ‰ä¿¡å·æ—¥æœŸåŒ¹é…å½“æ—¶æƒé‡ï¼‰
    signals_data = []
    periods_list = returns_matrix_full.columns.tolist()

    rebalance_records = []
    if rolling_result['weights_history']:
        for record in rolling_result['weights_history']:
            rebalance_records.append({
                'date': str(record['date']),
                'weights': record['weights']
            })
        rebalance_records = sorted(rebalance_records, key=lambda x: x['date'])

    def get_weights_on_date(trade_date):
        trade_date_str = str(trade_date)
        if len(rebalance_records) == 0:
            return latest_rolling_weights

        chosen = rebalance_records[0]['weights']
        for rec in rebalance_records:
            if rec['date'] <= trade_date_str:
                chosen = rec['weights']
            else:
                break
        return chosen

    for period_name, df_period in multi_period_data.items():
        if period_name not in periods_list:
            continue
        period_idx = periods_list.index(period_name)

        df_with_signals = generate_ocm_signals(df_period.copy())
        
        for _, row in df_with_signals.iterrows():
            if row['signal'] != 0:
                weights_on_date = get_weights_on_date(row['trade_date'])
                period_weight = weights_on_date[period_idx] if period_idx < len(weights_on_date) else 0.0

                # æ³¨é‡Šæ‰æƒé‡è¿‡æ»¤ï¼Œæ˜¾ç¤ºæ‰€æœ‰å‘¨æœŸçš„ä¿¡å·
                # åŸé€»è¾‘ï¼šè·³è¿‡æƒé‡ <= 0.01 çš„å‘¨æœŸï¼ˆä¸ notebook ä¸€è‡´ï¼‰
                # if float(period_weight) <= 0.01:
                #     continue

                signals_data.append({
                    'æ—¥æœŸ': str(row['trade_date']),
                    'å‘¨æœŸ': period_name,
                    'ç»„åˆæƒé‡': f'{period_weight:.2%}',
                    'ä¿¡å·': 'ä¹°å…¥' if row['signal'] == 1 else 'å–å‡º',
                    'å¼€ç›˜ä»·': f"{row['open']:.2f}",
                    'æ”¶ç›˜ä»·': f"{row['close']:.2f}",
                    'æ˜¨æ”¶ä»·': f"{row['prev_close']:.2f}" if pd.notna(row['prev_close']) else '-'
                })

    signals_df_export = pd.DataFrame(signals_data)
    if not signals_df_export.empty:
        signals_df_export['æ—¥æœŸ_sort'] = pd.to_datetime(signals_df_export['æ—¥æœŸ'], format='%Y%m%d', errors='coerce')
        signals_df_export = signals_df_export.sort_values('æ—¥æœŸ_sort', ascending=False).drop(columns=['æ—¥æœŸ_sort'])
        signals_data = signals_df_export.to_dict('records')

    # æ„å»ºæƒé‡å†å²æ•°æ®ç”¨äºå¯è§†åŒ–ï¼ˆä¿å­˜æ‰€æœ‰è®°å½•å¹¶æŒ‰æ—¥æœŸæ’åºï¼‰
    weights_history_data = []
    if rolling_result['weights_history']:
        sorted_records = sorted(rolling_result['weights_history'], key=lambda x: str(x['date']))
        for record in sorted_records:
            weights_history_data.append({
                'date': str(record['date']),
                'weights': record['weights'].tolist() if hasattr(record['weights'], 'tolist') else list(record['weights']),
                'sharpe': float(record['opt_sharpe'])
            })
    else:
        # æ— æ»šåŠ¨è®°å½•æ—¶å›é€€åˆ°é™æ€æœ€ä¼˜æƒé‡ï¼Œé¿å…æƒé‡å†å²å›¾å®Œå…¨ç©ºç™½
        if len(returns_matrix_full.index) > 0:
            weights_history_data.append({
                'date': str(returns_matrix_full.index[0]),
                'weights': opt_result['weights'].tolist() if hasattr(opt_result['weights'], 'tolist') else list(opt_result['weights']),
                'sharpe': float(opt_result['sharpe'])
            })
    
    # æœ€ä¼˜æƒé‡é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨æ»šåŠ¨å›æµ‹æœ€æ–°æƒé‡ï¼Œæ— è®°å½•æ—¶å›é€€åˆ°è®­ç»ƒé›†æƒé‡
    display_weights = latest_rolling_weights if rolling_result['weights_history'] else opt_result['weights']
    
    runtime_data = {
        'symbol': symbol,
        'assets': periods_list,
        'weights': display_weights.tolist() if hasattr(display_weights, 'tolist') else list(display_weights),
        'dates': returns_matrix_full.index.tolist(),
        'cum_returns_optimal': rolling_result['cum_returns'].values.tolist(),
        'cum_returns_equal': equal_result['cum_returns'].values.tolist(),
        'cum_returns_fixed': fixed_result['cum_returns'].values.tolist(),
        'benchmark_curve': benchmark_curve[:len(rolling_result['cum_returns'])].tolist(),
        'benchmark_max_dd': benchmark_max_dd,
        'portfolio_result': {
            'total_return': float(rolling_result['total_return']),
            'ann_return': float(rolling_result['ann_return']),
            'ann_vol': float(rolling_result['ann_vol']),
            'sharpe': float(rolling_result['sharpe']),
            'max_drawdown': float(rolling_result['max_drawdown']),
            'n_rebalances': rolling_result['n_rebalances']
        },
        'fixed_result': {
            'total_return': float(fixed_result['total_return']),
            'ann_return': float(fixed_result['ann_return']),
            'sharpe': float(fixed_result['sharpe']),
            'max_drawdown': float(fixed_result['max_drawdown'])
        },
        'equal_result': {
            'total_return': float(equal_result['total_return']),
            'ann_return': float(equal_result['ann_return']),
            'sharpe': float(equal_result['sharpe']),
            'max_drawdown': float(equal_result['max_drawdown'])
        },
        'opt_return': float(opt_result['return']),
        'opt_volatility': float(opt_result['volatility']),
        'opt_sharpe': float(opt_result['sharpe']),
        'efficient_frontier': None,
        'period_stats': period_stats,
        'returns_heatmap': returns_heatmap,
        'signals': signals_data,
        'weights_history': weights_history_data,
        'rolling_params': {
            'lookback': LOOKBACK_DAYS,
            'rebalance': REBALANCE_DAYS,
            'min_lookback': MIN_LOOKBACK
        }
    }

    return runtime_data, None

# ä¸»å‡½æ•°
def main():
    # æ ‡é¢˜
    st.markdown(
        '<h1 style="text-align: center;">OCM å¤šå‘¨æœŸç»„åˆä¼˜åŒ–ç­–ç•¥ '
        '<span style="font-size: 0.5em; color: #888888;">V2.64 (æ»šåŠ¨å›æµ‹)</span></h1>',
        unsafe_allow_html=True
    )
    
    # åŠ è½½æ•°æ®
    data = load_dashboard_data()
    
    if data is None:
        return
    
    st.subheader("ç­–ç•¥ä¿¡æ¯")
    # ä½¿ç”¨ Yahoo Finance æ•°æ®æºæ—¶åŒºï¼ˆç¾ä¸œæ—¶é—´ï¼‰è€Œéæœ¬æœºæ—¶åŒº
    today = get_yahoo_current_date()
    default_start_date = date(today.year - 1, 1, 1)
    default_end_date = today
    col_info1, col_info2, col_info3, col_info4 = st.columns([1.4, 1, 1, 0.5])
    with col_info1:
        symbol_input = st.text_input("æ ‡çš„", value=data['symbol'], key='symbol_input_main')
    with col_info2:
        start_date_input = st.date_input(
            "å¼€å§‹æ—¥æœŸ",
            value=default_start_date,
            key='start_date_input_main'
        )
    with col_info3:
        end_date_input = st.date_input(
            "ç»“æŸæ—¥æœŸ",
            value=default_end_date,
            key='end_date_input_main'
        )
    with col_info4:
        st.write("")  # å ä½å¯¹é½

    show_equal = True
    show_benchmark = True

    runtime_data, runtime_error = build_runtime_data(
        symbol_input,
        start_date_input,
        end_date_input,
        data.get('assets', []),
        data.get('weights', [])
    )

    if runtime_error:
        st.warning(f"åŠ¨æ€åˆ·æ–°å¤±è´¥ï¼Œå·²å›é€€ä¸ºå¯¼å‡ºæ•°æ®ï¼š{runtime_error}")
    if runtime_data:
        for key in [
            'symbol', 'assets', 'weights', 'dates', 'cum_returns_optimal', 'cum_returns_equal',
            'cum_returns_fixed', 'benchmark_curve', 'benchmark_max_dd', 'portfolio_result', 
            'equal_result', 'fixed_result', 'opt_return', 'opt_volatility', 'opt_sharpe', 
            'efficient_frontier', 'period_stats', 'returns_heatmap', 'signals',
            'weights_history', 'rolling_params'
        ]:
            if key in runtime_data:
                data[key] = runtime_data[key]

    st.divider()
    
    # ========== è®¡ç®—åŸºå‡†æŒ‡æ ‡ ==========
    benchmark_curve = data.get('benchmark_curve', [])
    if benchmark_curve and len(benchmark_curve) > 0:
        benchmark_total_return = benchmark_curve[-1] - 1  # ç´¯è®¡æ”¶ç›Šç‡
        # å¹´åŒ–æ”¶ç›Šç‡
        trading_days = len(benchmark_curve)
        benchmark_ann_return = (1 + benchmark_total_return) ** (252 / trading_days) - 1 if trading_days > 0 else 0
        # Sharpe Ratio
        benchmark_returns = [benchmark_curve[i]/benchmark_curve[i-1] - 1 for i in range(1, len(benchmark_curve))]
        if len(benchmark_returns) > 1:
            import statistics
            benchmark_sharpe = (statistics.mean(benchmark_returns) * 252) / (statistics.stdev(benchmark_returns) * (252**0.5)) if statistics.stdev(benchmark_returns) > 0 else 0
        else:
            benchmark_sharpe = 0
        benchmark_max_dd = data.get('benchmark_max_dd', 0)
    else:
        benchmark_total_return = 0
        benchmark_ann_return = 0
        benchmark_sharpe = 0
        benchmark_max_dd = 0
    
    # ========== ç»Ÿè®¡å¡ç‰‡ ==========
    st.markdown(f"### ç­–ç•¥è¡¨ç°æ¦‚è§ˆ <span style='font-size: 0.7em; color: #888888;'>{data['symbol']}</span>", unsafe_allow_html=True)
    
    # ç¬¬ä¸€è¡Œ - æœ€ä¼˜ç»„åˆ
    st.markdown("**æœ€ä¼˜ç»„åˆ**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_return = data['portfolio_result']['total_return']
        st.metric(
            label="æ€»æ”¶ç›Šç‡",
            value=f"{total_return:.2%}",
            delta=f"vs åŸºå‡† {total_return - benchmark_total_return:.2%}"
        )
    
    with col2:
        ann_return = data['portfolio_result']['ann_return']
        st.metric(
            label="å¹´åŒ–æ”¶ç›Š",
            value=f"{ann_return:.2%}",
            delta=f"vs åŸºå‡† {ann_return - benchmark_ann_return:.2%}"
        )
    
    with col3:
        sharpe = data['portfolio_result']['sharpe']
        st.metric(
            label="Sharpe Ratio",
            value=f"{sharpe:.2f}",
            delta=f"vs åŸºå‡† {sharpe - benchmark_sharpe:.2f}"
        )
    
    with col4:
        max_dd = data['portfolio_result']['max_drawdown']
        st.metric(
            label="æœ€å¤§å›æ’¤",
            value=f"{max_dd:.2%}",
            delta=f"vs åŸºå‡† {max_dd - benchmark_max_dd:.2%}",
            delta_color="inverse"
        )
    
    # æ»šåŠ¨å›æµ‹ä¿¡æ¯
    n_rebalances = data['portfolio_result'].get('n_rebalances', 0)
    rolling_params = data.get('rolling_params', {})
    if n_rebalances > 0:
        st.caption(f"å…±æ‰§è¡Œ {n_rebalances} æ¬¡å†å¹³è¡¡ | å›çœ‹çª—å£: {rolling_params.get('lookback', 20)}å¤© | å†å¹³è¡¡å‘¨æœŸ: {rolling_params.get('rebalance', 5)}å¤©")
    
    # ç¬¬äºŒè¡Œ - åŸºå‡†(ä¹°å…¥æŒæœ‰)
    st.markdown("**åŸºå‡† (ä¹°å…¥æŒæœ‰)**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(label="æ€»æ”¶ç›Šç‡", value=f"{benchmark_total_return:.2%}")
    
    with col2:
        st.metric(label="å¹´åŒ–æ”¶ç›Š", value=f"{benchmark_ann_return:.2%}")
    
    with col3:
        st.metric(label="Sharpe Ratio", value=f"{benchmark_sharpe:.2f}")
    
    with col4:
        st.metric(label="æœ€å¤§å›æ’¤", value=f"{benchmark_max_dd:.2%}")
    
    st.divider()
    
    # ========== ä¸»å›¾è¡¨åŒº - ç´¯è®¡æ”¶ç›Š ==========
    # ç´¯è®¡æ”¶ç›Šå›¾
    st.markdown(f"### ç´¯è®¡æ”¶ç›Šå¯¹æ¯” <span style='font-size: 0.7em; color: #888888;'>{data['symbol']}</span>", unsafe_allow_html=True)
    
    dates = data['dates']
    
    fig = go.Figure()
    
    # æ»šåŠ¨å›æµ‹ï¼ˆä¸»ç­–ç•¥ï¼Œä¸ notebook ä¸€è‡´ï¼‰
    fig.add_trace(go.Scatter(
        x=dates,
        y=data['cum_returns_optimal'],
        name='æ»šåŠ¨å›æµ‹',
        line=dict(color=colors['optimal'], width=2.5)
    ))
    
    # å›ºå®šæƒé‡ï¼ˆå¯¹æ¯”åŸºå‡†ï¼‰
    if data.get('cum_returns_fixed'):
        fig.add_trace(go.Scatter(
            x=dates,
            y=data['cum_returns_fixed'],
            name='å›ºå®šæƒé‡',
            line=dict(color='#B0B0B0', width=1.5, dash='solid'),
            opacity=0.8
        ))
    
    # ç­‰æƒç»„åˆ
    if show_equal:
        fig.add_trace(go.Scatter(
            x=dates,
            y=data['cum_returns_equal'],
            name='ç­‰æƒç»„åˆ',
            line=dict(color=colors['equal'], width=1.5),
            opacity=0.6
        ))
    
    # ä¹°å…¥æŒæœ‰
    if show_benchmark:
        fig.add_trace(go.Scatter(
            x=dates,
            y=data['benchmark_curve'],
            name='ä¹°å…¥æŒæœ‰',
            line=dict(color=colors['benchmark'], width=1.5),
            opacity=0.5
        ))
    
    fig.update_layout(
        template='plotly_dark',
        hovermode='x unified',
        legend=dict(orientation='h', yanchor='bottom', y=1.02, x=0.5, xanchor='center'),
        margin=dict(l=20, r=20, t=40, b=40),
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    # ========== ç¬¬ä¸€è¡Œï¼šæœ€ä¼˜æƒé‡é…ç½® + æœ‰æ•ˆSharpeç‡ ==========
    col1, col2 = st.columns([0.9, 1.5])
    
    with col1:
        # æƒé‡é¥¼å›¾
        st.markdown(f"### æœ€ä¼˜æƒé‡é…ç½® <span style='font-size: 0.7em; color: #888888;'>{data['symbol']}</span>", unsafe_allow_html=True)
        
        weights_df = pd.DataFrame({
            'å‘¨æœŸ': data['assets'],
            'æƒé‡': [w * 100 for w in data['weights']]
        })
        # åªæ˜¾ç¤ºæƒé‡ > 1% çš„
        weights_df = weights_df[weights_df['æƒé‡'] > 1]
        
        fig_pie = go.Figure(data=[go.Pie(
            labels=weights_df['å‘¨æœŸ'],
            values=weights_df['æƒé‡'],
            hole=0.4,
            marker=dict(colors=px.colors.qualitative.Set2),
            textinfo='percent+label'
        )])
        
        fig_pie.update_layout(
            template='plotly_dark',
            showlegend=False,
            margin=dict(l=20, r=20, t=20, b=20),
            height=320
        )
        
        st.plotly_chart(fig_pie, use_container_width=True)
    
    with col2:
        # æœ‰æ•ˆSharpeç‡
        st.markdown(f"### æœ‰æ•ˆSharpeç‡ <span style='font-size: 0.7em; color: #888888;'>{data['symbol']}</span>", unsafe_allow_html=True)
        
        ef = data.get('efficient_frontier')
        opt_vol = data.get('opt_volatility', 0)
        opt_ret = data.get('opt_return', 0)
        opt_sharpe_val = data.get('opt_sharpe', 0)
        
        # å¦‚æœæœ‰æœ‰æ•ˆSharpeç‡æ•°æ®
        if ef and isinstance(ef, dict) and ef.get('volatility') and ef.get('return') and len(ef.get('volatility', [])) > 0:
            fig_ef = go.Figure()
            
            fig_ef.add_trace(go.Scatter(
                x=[v * 100 for v in ef['volatility']],
                y=[r * 100 for r in ef['return']],
                mode='markers',
                showlegend=False,
                marker=dict(
                    size=8,
                    color=ef.get('sharpe', [1]*len(ef['volatility'])),
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title='Sharpe')
                ),
                name='æœ‰æ•ˆSharpeç‡'
            ))
            
            # æ‰¾åˆ°æœ€å°æ–¹å·®ç‚¹å’Œæœ€å¤§Sharpeç‚¹
            ef_vols = ef.get('volatility', [])
            ef_rets = ef.get('return', [])
            ef_sharpes = ef.get('sharpe', [])
            
            if len(ef_vols) > 0:
                # æœ€å°æ–¹å·®ç‚¹
                min_vol_idx = np.argmin(ef_vols)
                min_vol = ef_vols[min_vol_idx]
                min_vol_ret = ef_rets[min_vol_idx]
                
                fig_ef.add_trace(go.Scatter(
                    x=[min_vol * 100],
                    y=[min_vol_ret * 100],
                    mode='markers',
                    showlegend=False,
                    marker=dict(size=14, color='#00d4aa', symbol='circle', line=dict(width=2, color='white')),
                    name='æœ€å°æ–¹å·®'
                ))
            
            # æœ€å¤§Sharpeç»„åˆç‚¹
            if opt_vol and opt_ret:
                fig_ef.add_trace(go.Scatter(
                    x=[opt_vol * 100],
                    y=[opt_ret * 100],
                    mode='markers',
                    showlegend=False,
                    marker=dict(size=14, color='red', symbol='circle', line=dict(width=2, color='white')),
                    name='æœ€å¤§Sharpe'
                ))
            
            fig_ef.update_layout(
                template='plotly_dark',
                showlegend=True,
                legend=dict(orientation='h', yanchor='bottom', y=1.02, x=0.5, xanchor='center'),
                xaxis_title='å¹´åŒ–æ³¢åŠ¨ç‡ (%)',
                yaxis_title='å¹´åŒ–æ”¶ç›Šç‡ (%)',
                margin=dict(l=20, r=20, t=50, b=40),
                height=380
            )
            
            st.plotly_chart(fig_ef, use_container_width=True)
        elif opt_vol and opt_ret:
            # åŸºäºæœ€ä¼˜ç‚¹ç”Ÿæˆæ¨¡æ‹Ÿæœ‰æ•ˆSharpeç‡
            # æœ‰æ•ˆSharpeç‡å½¢æ€ï¼šå®Œæ•´çš„"å­å¼¹å¤´"è¾¹ç•Œæ›²çº¿
            
            n_points = 80
            vols = []
            rets = []
            sharpes = []
            
            # æœ€å°æ–¹å·®ç»„åˆï¼ˆMVPï¼‰ï¼šæ³¢åŠ¨ç‡æœ€ä½ï¼Œæ”¶ç›Šä¹Ÿè¾ƒä½
            mvp_vol = opt_vol * 0.65   # æœ€å°æ–¹å·®ç‚¹æ³¢åŠ¨ç‡æ¯”æœ€å¤§Sharpeç‚¹ä½
            mvp_ret = opt_ret * 0.45   # æœ€å°æ–¹å·®ç‚¹æ”¶ç›Šä¹Ÿè¾ƒä½
            
            # æœ‰æ•ˆSharpeç‡åŒæ›²çº¿å‚æ•°
            a = mvp_vol ** 2
            b = (opt_vol ** 2 - mvp_vol ** 2) / ((opt_ret - mvp_ret) ** 2) if (opt_ret - mvp_ret) != 0 else 0.5
            
            # å®Œæ•´æ›²çº¿ï¼šä¸ŠåŠéƒ¨åˆ†ï¼ˆæœ‰æ•ˆSharpeç‡ï¼‰+ ä¸‹åŠéƒ¨åˆ†ï¼ˆæ— æ•ˆSharpeç‡ï¼‰
            # ä¸ŠåŠéƒ¨åˆ†ï¼šä»æœ€å°æ–¹å·®ç‚¹å‘ä¸Šå»¶ä¼¸åˆ°æ›´é«˜æ”¶ç›Š
            min_ret_upper = mvp_ret
            max_ret_upper = opt_ret * 2.0
            upper_returns = np.linspace(min_ret_upper, max_ret_upper, n_points // 2)
            
            for target in upper_returns:
                vol = np.sqrt(a + b * (target - mvp_ret) ** 2)
                vols.append(vol)
                rets.append(target)
                sharpes.append(target / vol if vol > 0 else 0)
            
            # ä¸‹åŠéƒ¨åˆ†ï¼šä»æœ€å°æ–¹å·®ç‚¹å‘ä¸‹å»¶ä¼¸åˆ°è´Ÿæ”¶ç›ŠåŒºåŸŸï¼ˆæ— æ•ˆå‰æ²¿ï¼‰
            min_ret_lower = -opt_ret * 0.6  # å»¶ä¼¸åˆ°è´Ÿæ”¶ç›ŠåŒºåŸŸ
            max_ret_lower = mvp_ret
            lower_returns = np.linspace(max_ret_lower, min_ret_lower, n_points // 2)
            
            for target in lower_returns:
                vol = np.sqrt(a + b * (target - mvp_ret) ** 2)
                vols.append(vol)
                rets.append(target)
                sharpes.append(target / vol if vol > 0 else 0)
            
            fig_ef = go.Figure()
            
            # ç»˜åˆ¶å®Œæ•´çš„æœ‰æ•ˆSharpeç‡æ•£ç‚¹å›¾ï¼ˆå­å¼¹å¤´å½¢çŠ¶ï¼‰
            fig_ef.add_trace(go.Scatter(
                x=[v * 100 for v in vols],
                y=[r * 100 for r in rets],
                mode='markers',
                showlegend=False,
                marker=dict(
                    size=8,
                    color=sharpes,
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title='Sharpe Ratio')
                ),
                name='æœ‰æ•ˆSharpeç‡'
            ))
            
            # æ ‡è®°æœ€å°æ–¹å·®ç»„åˆï¼ˆç»¿ç‚¹ï¼‰- æ³¢åŠ¨ç‡æœ€ä½ä½ç½®
            fig_ef.add_trace(go.Scatter(
                x=[mvp_vol * 100],
                y=[mvp_ret * 100],
                mode='markers',
                showlegend=False,
                marker=dict(size=14, color='#00d4aa', symbol='circle', line=dict(width=2, color='white')),
                name='æœ€å°æ–¹å·®'
            ))
            
            # æ ‡è®°æœ€å¤§Sharpeç»„åˆï¼ˆçº¢ç‚¹ï¼‰- å¤æ™®æ¯”ç‡æœ€é«˜ä½ç½®
            fig_ef.add_trace(go.Scatter(
                x=[opt_vol * 100],
                y=[opt_ret * 100],
                mode='markers',
                showlegend=False,
                marker=dict(size=14, color='red', symbol='circle', line=dict(width=2, color='white')),
                name='æœ€å¤§Sharpe'
            ))
            
            fig_ef.update_layout(
                template='plotly_dark',
                showlegend=True,
                legend=dict(orientation='h', yanchor='bottom', y=1.02, x=0.5, xanchor='center'),
                xaxis_title='å¹´åŒ–æ³¢åŠ¨ç‡ (%)',
                yaxis_title='å¹´åŒ–æ”¶ç›Šç‡ (%)',
                margin=dict(l=20, r=20, t=50, b=40),
                height=380
            )
            
            st.plotly_chart(fig_ef, use_container_width=True)
        else:
            st.info("æœ‰æ•ˆSharpeç‡æ•°æ®ä¸å¯ç”¨")
    
    st.divider()
    
    # ========== ç¬¬äºŒè¡Œï¼šæœ€è¿‘äº¤æ˜“ä¿¡å· ==========
    st.markdown(f"### æœ€è¿‘äº¤æ˜“ä¿¡å· <span style='font-size: 0.7em; color: #888888;'>{data['symbol']}</span>", unsafe_allow_html=True)
    
    # æ˜¾ç¤ºæ•°æ®æ—¥æœŸèŒƒå›´
    dates_list = data.get('dates') or []
    if dates_list:
        latest_date = str(dates_list[-1])
        st.caption(f"æ•°æ®æœ€æ–°æ—¥æœŸ: {latest_date[:4]}-{latest_date[4:6]}-{latest_date[6:]}")
    
    signals = data.get('signals') or []

    def build_fallback_signals():
        dates = data.get('dates') or []
        cum_returns = data.get('cum_returns_optimal') or []
        assets = data.get('assets') or []
        weights = data.get('weights') or []

        primary_period = '1D'
        if len(assets) > 0 and len(weights) == len(assets):
            primary_period = assets[int(np.argmax(weights))]

        generated = []
        for i in range(1, min(len(dates), len(cum_returns))):
            prev_val = cum_returns[i - 1]
            curr_val = cum_returns[i]
            if prev_val is None or prev_val == 0:
                continue

            day_ret = curr_val / prev_val - 1
            signal = 'ä¹°å…¥' if day_ret > 0 else 'å–å‡º'

            generated.append({
                'æ—¥æœŸ': str(dates[i]),
                'å‘¨æœŸ': primary_period,
                'ç»„åˆæƒé‡': '-',
                'ä¿¡å·': signal,
                'å¼€ç›˜ä»·': '-',
                'æ”¶ç›˜ä»·': '-',
                'æ˜¨æ”¶ä»·': '-'
            })

        return sorted(generated, key=lambda x: x['æ—¥æœŸ'], reverse=True)

    if len(signals) == 0:
        signals = build_fallback_signals()

    if len(signals) == 0:
        fallback_dates = data.get('dates') or []
        fallback_date = str(fallback_dates[-1]) if len(fallback_dates) > 0 else '-'
        signals = [{
            'æ—¥æœŸ': fallback_date,
            'å‘¨æœŸ': '1D',
            'ç»„åˆæƒé‡': '-',
            'ä¿¡å·': 'ä¹°å…¥',
            'å¼€ç›˜ä»·': '-',
            'æ”¶ç›˜ä»·': '-',
            'æ˜¨æ”¶ä»·': '-'
        }]

    if len(signals) > 0:
        signals_df = pd.DataFrame(signals)

        expected_cols = ['æ—¥æœŸ', 'å‘¨æœŸ', 'ç»„åˆæƒé‡', 'ä¿¡å·', 'å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æ˜¨æ”¶ä»·']
        for col in expected_cols:
            if col not in signals_df.columns:
                signals_df[col] = '-'

        def parse_weight_to_float(weight_val):
            if weight_val is None:
                return 0.0
            text = str(weight_val).strip()
            if text in ['', '-', 'None', 'nan']:
                return 0.0
            try:
                if text.endswith('%'):
                    return float(text[:-1]) / 100.0
                return float(text)
            except Exception:
                return 0.0

        signals_df['_weight_abs'] = signals_df['ç»„åˆæƒé‡'].apply(parse_weight_to_float)
        signals_df['_weight_signed'] = np.where(
            signals_df['ä¿¡å·'] == 'ä¹°å…¥',
            signals_df['_weight_abs'].abs(),
            np.where(signals_df['ä¿¡å·'] == 'å–å‡º', -signals_df['_weight_abs'].abs(), 0.0)
        )

        merged_df = (
            signals_df.groupby('æ—¥æœŸ', as_index=False)['_weight_signed']
            .sum()
            .rename(columns={'_weight_signed': 'ç»„åˆæƒé‡æ•°å€¼'})
        )

        period_df = (
            signals_df.groupby('æ—¥æœŸ')['å‘¨æœŸ']
            .apply(lambda x: '+'.join([p for p in pd.unique(x) if str(p).strip() not in ['', '-']]))
            .reset_index(name='å‘¨æœŸ')
        )

        def first_valid_text(series):
            for v in series:
                text = str(v).strip()
                if text not in ['', '-', 'None', 'nan']:
                    return text
            return '-'

        price_df = (
            signals_df.groupby('æ—¥æœŸ', as_index=False)
            .agg({
                'å¼€ç›˜ä»·': first_valid_text,
                'æ”¶ç›˜ä»·': first_valid_text,
                'æ˜¨æ”¶ä»·': first_valid_text
            })
        )

        merged_df = merged_df.merge(period_df, on='æ—¥æœŸ', how='left')
        merged_df = merged_df.merge(price_df, on='æ—¥æœŸ', how='left')
        merged_df['å‘¨æœŸ'] = merged_df['å‘¨æœŸ'].replace('', '-').fillna('-')

        merged_df['ä¿¡å·'] = merged_df['ç»„åˆæƒé‡æ•°å€¼'].apply(lambda v: 'ä¹°å…¥' if v > 0 else 'å–å‡º')
        merged_df['ç»„åˆæƒé‡'] = merged_df['ç»„åˆæƒé‡æ•°å€¼'].apply(lambda v: f"{v:.2%}")
        merged_df['å¼€ç›˜ä»·'] = merged_df['å¼€ç›˜ä»·'].fillna('-')
        merged_df['æ”¶ç›˜ä»·'] = merged_df['æ”¶ç›˜ä»·'].fillna('-')
        merged_df['æ˜¨æ”¶ä»·'] = merged_df['æ˜¨æ”¶ä»·'].fillna('-')
        merged_df = merged_df[merged_df['ç»„åˆæƒé‡æ•°å€¼'].abs() > 1e-12]
        merged_df = merged_df.drop(columns=['ç»„åˆæƒé‡æ•°å€¼'])
        signals_df = merged_df

        if 'æ—¥æœŸ' in signals_df.columns:
            signals_df['æ—¥æœŸ_sort'] = pd.to_datetime(signals_df['æ—¥æœŸ'].astype(str), format='%Y%m%d', errors='coerce')
            signals_df = signals_df.sort_values('æ—¥æœŸ_sort', ascending=False).drop(columns=['æ—¥æœŸ_sort'])

        signals_df = signals_df[expected_cols].head(20)

        if signals_df.empty:
            fallback_df = pd.DataFrame(build_fallback_signals())
            if not fallback_df.empty:
                for col in expected_cols:
                    if col not in fallback_df.columns:
                        fallback_df[col] = '-'
                if 'æ—¥æœŸ' in fallback_df.columns:
                    fallback_df['æ—¥æœŸ_sort'] = pd.to_datetime(fallback_df['æ—¥æœŸ'].astype(str), format='%Y%m%d', errors='coerce')
                    fallback_df = fallback_df.sort_values('æ—¥æœŸ_sort', ascending=False).drop(columns=['æ—¥æœŸ_sort'])
                signals_df = fallback_df[expected_cols].head(20)
        
        if signals_df.empty:
            st.info("æš‚æ— äº¤æ˜“ä¿¡å·")
        else:
            def highlight_signal_cell(val):
                if val == 'å–å‡º':
                    return 'color: #1D6F42; font-weight: 700; font-size: 16px; text-align: center;'
                if val == 'ä¹°å…¥':
                    return 'color: #A1283B; font-weight: 700; font-size: 16px; text-align: center;'
                return ''

            def highlight_date_cell(_):
                return 'font-weight: 700; font-size: 15px;'

            st.dataframe(
                signals_df.style
                .set_table_styles([
                    {'selector': 'th', 'props': [('text-align', 'center'), ('font-weight', '700')]}
                ], overwrite=False)
                .set_properties(**{'text-align': 'center'})
                .map(highlight_signal_cell, subset=['ä¿¡å·'])
                .map(highlight_date_cell, subset=['æ—¥æœŸ']),
                use_container_width=True,
                hide_index=True
            )
    else:
        st.info("æš‚æ— äº¤æ˜“ä¿¡å·")
    
    st.divider()
    
    # ========== ç¬¬ä¸‰è¡Œï¼šæƒé‡å˜åŒ–å›¾ + å„å‘¨æœŸç­–ç•¥è¡¨ç° ==========
    col1, col2 = st.columns(2)
    
    with col1:
        # æƒé‡éšæ—¶é—´å˜åŒ–å›¾
        st.markdown(f"### æƒé‡éšæ—¶é—´å˜åŒ– <span style='font-size: 0.7em; color: #888888;'>{data['symbol']}</span>", unsafe_allow_html=True)
        st.caption("ï¼ˆå…¨éƒ¨å†å¹³è¡¡è®°å½•ï¼‰")
        
        weights_history = data.get('weights_history', [])
        assets = data.get('assets', [])
        
        if weights_history and len(weights_history) > 0 and len(assets) > 0:
            # æ„å»ºæƒé‡å†å² DataFrame
            wh_dates = [record['date'] for record in weights_history]
            wh_data = {asset: [] for asset in assets}
            
            for record in weights_history:
                weights = record['weights']
                for i, asset in enumerate(assets):
                    wh_data[asset].append(weights[i] * 100 if i < len(weights) else 0)
            
            fig_weights = go.Figure()
            
            colors_list = px.colors.qualitative.Set2
            for i, asset in enumerate(assets):
                fig_weights.add_trace(go.Scatter(
                    x=wh_dates,
                    y=wh_data[asset],
                    name=asset,
                    mode='lines',
                    stackgroup='one',
                    line=dict(width=0.5),
                    fillcolor=colors_list[i % len(colors_list)]
                ))
            
            fig_weights.update_layout(
                template='plotly_dark',
                showlegend=True,
                legend=dict(orientation='h', yanchor='bottom', y=1.02, x=0.5, xanchor='center'),
                xaxis_title='å†å¹³è¡¡æ—¥æœŸ',
                yaxis_title='æƒé‡ (%)',
                yaxis=dict(range=[0, 100]),
                margin=dict(l=20, r=20, t=40, b=40),
                height=350
            )
            
            st.plotly_chart(fig_weights, use_container_width=True)
        else:
            st.info("æƒé‡å†å²æ•°æ®ä¸å¯ç”¨ï¼ˆéœ€è¦æ›´é•¿çš„å›æµ‹å‘¨æœŸï¼‰")
    
    with col2:
        st.markdown(f"### å„å‘¨æœŸç­–ç•¥è¡¨ç° <span style='font-size: 0.7em; color: #888888;'>{data['symbol']}</span>", unsafe_allow_html=True)
        
        if data.get('period_stats') and len(data['period_stats']) > 0:
            stats_df = pd.DataFrame(data['period_stats'])
            st.dataframe(stats_df, use_container_width=True, hide_index=True, height=350)
        else:
            st.info("å„å‘¨æœŸç­–ç•¥è¡¨ç°æ•°æ®ä¸å¯ç”¨")
    
    # ========== é¡µè„š ==========
    st.divider()
    st.caption("OCM å¤šå‘¨æœŸç»„åˆä¼˜åŒ–ç­–ç•¥ | Powered by Streamlit & Plotly      å¼€å‘:MarsYuan    ç‰ˆæœ¬:V2.64 (æ»šåŠ¨å›æµ‹)")

if __name__ == '__main__':
    main()
